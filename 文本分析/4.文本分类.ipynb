{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本分类是将文本文档或句子分配到预定义的类别或标签的过程。以下是一些主要的文本分类方法及其基本代码示例：\n",
    "\n",
    "1. **朴素贝叶斯分类器**:\n",
    "   朴素贝叶斯是基于贝叶斯定理的一种简单的概率分类器。\n",
    "\n",
    "   ``` python\n",
    "   from sklearn.naive_bayes import MultinomialNB\n",
    "   from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "   vectorizer = TfidfVectorizer()\n",
    "   X = vectorizer.fit_transform(texts)\n",
    "   clf = MultinomialNB()\n",
    "   clf.fit(X, labels)\n",
    "   predictions = clf.predict(X)\n",
    "   ```\n",
    "\n",
    "2. **支持向量机 (SVM)**:\n",
    "   SVM是一个监督学习算法，用于分类或回归问题。\n",
    "\n",
    "   ``` python\n",
    "   from sklearn.svm import SVC\n",
    "\n",
    "   clf = SVC(kernel=\"linear\")\n",
    "   clf.fit(X, labels)\n",
    "   predictions = clf.predict(X)\n",
    "   ```\n",
    "\n",
    "3. **决策树和随机森林**:\n",
    "   决策树是一个树形模型，随机森林是决策树的集合。\n",
    "\n",
    "   ``` python\n",
    "   from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "   clf = RandomForestClassifier(n_estimators=100)\n",
    "   clf.fit(X, labels)\n",
    "   predictions = clf.predict(X)\n",
    "   ```\n",
    "\n",
    "4. **Logistic Regression**:\n",
    "   尽管名为回归，但逻辑回归实际上是一个分类算法。\n",
    "\n",
    "   ``` python\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "   clf = LogisticRegression()\n",
    "   clf.fit(X, labels)\n",
    "   predictions = clf.predict(X)\n",
    "   ```\n",
    "\n",
    "5. **深度学习 (如CNN, RNN, BERT)**:\n",
    "   深度学习方法，特别是卷积神经网络 (CNN) 和循环神经网络 (RNN)，在文本分类任务上表现出色。\n",
    "\n",
    "   ``` python\n",
    "   # 这需要使用深度学习库如TensorFlow或PyTorch\n",
    "   # 下面是一个简单的TensorFlow Keras示例\n",
    "   from tensorflow.keras.models import Sequential\n",
    "   from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "\n",
    "   model = Sequential()\n",
    "   model.add(Embedding(input_dim=10000, output_dim=16))\n",
    "   model.add(GlobalAveragePooling1D())\n",
    "   model.add(Dense(1, activation='sigmoid'))\n",
    "   \n",
    "   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "   model.fit(X_train, y_train, epochs=10, batch_size=512, validation_data=(X_val, y_val))\n",
    "   predictions = model.predict(X_test)\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持向量机分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love machine learning\n",
      "Predicted Class: Positive\n",
      "\n",
      "Text: I hate coding bugs\n",
      "Predicted Class: Positive\n",
      "\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的库\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 准备数据\n",
    "texts = [\n",
    "    \"I love machine learning\",\n",
    "    \"I hate coding bugs\",\n",
    "    \"Deep learning is fascinating\",\n",
    "    \"Programming is like magic\",\n",
    "    \"Bugs can be annoying\",\n",
    "    \"Machine learning opens many opportunities\"\n",
    "]\n",
    "labels = [1, 0, 1, 1, 0, 1]  # 1表示正面情感，0表示负面情感\n",
    "\n",
    "# 数据预处理\n",
    "# 将数据分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用TfidfVectorizer将文本转化为向量\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 使用SVM进行分类\n",
    "# 初始化SVM分类器\n",
    "clf = SVC(kernel='linear')  # 使用线性核函数\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# 打印每一个测试样本及其预测的类别\n",
    "for text, prediction in zip(X_test, y_pred):\n",
    "    print(f\"Text: {text}\\nPredicted Class: {'Positive' if prediction == 1 else 'Negative'}\\n\")\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 - 2s - loss: 0.6929 - accuracy: 0.7500 - 2s/epoch - 2s/step\n",
      "Epoch 2/30\n",
      "1/1 - 0s - loss: 0.6863 - accuracy: 0.7500 - 4ms/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1/1 - 0s - loss: 0.6811 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "Epoch 4/30\n",
      "1/1 - 0s - loss: 0.6758 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1/1 - 0s - loss: 0.6702 - accuracy: 0.7500 - 4ms/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1/1 - 0s - loss: 0.6646 - accuracy: 0.7500 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1/1 - 0s - loss: 0.6590 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1/1 - 0s - loss: 0.6533 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1/1 - 0s - loss: 0.6471 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "1/1 - 0s - loss: 0.6406 - accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
      "Epoch 11/30\n",
      "1/1 - 0s - loss: 0.6337 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 12/30\n",
      "1/1 - 0s - loss: 0.6264 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "Epoch 13/30\n",
      "1/1 - 0s - loss: 0.6185 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "Epoch 14/30\n",
      "1/1 - 0s - loss: 0.6102 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "1/1 - 0s - loss: 0.6014 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "Epoch 16/30\n",
      "1/1 - 0s - loss: 0.5923 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1/1 - 0s - loss: 0.5827 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "1/1 - 0s - loss: 0.5724 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 19/30\n",
      "1/1 - 0s - loss: 0.5617 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "Epoch 20/30\n",
      "1/1 - 0s - loss: 0.5505 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
      "Epoch 21/30\n",
      "1/1 - 0s - loss: 0.5389 - accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "Epoch 22/30\n",
      "1/1 - 0s - loss: 0.5269 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "Epoch 23/30\n",
      "1/1 - 0s - loss: 0.5145 - accuracy: 0.7500 - 33ms/epoch - 33ms/step\n",
      "Epoch 24/30\n",
      "1/1 - 0s - loss: 0.5016 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "Epoch 25/30\n",
      "1/1 - 0s - loss: 0.4883 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "Epoch 26/30\n",
      "1/1 - 0s - loss: 0.4745 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "1/1 - 0s - loss: 0.4602 - accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
      "Epoch 28/30\n",
      "1/1 - 0s - loss: 0.4456 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "Epoch 29/30\n",
      "1/1 - 0s - loss: 0.4306 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
      "Epoch 30/30\n",
      "1/1 - 0s - loss: 0.4151 - accuracy: 0.7500 - 5ms/epoch - 5ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 引入所需的库和模块\n",
    "import tensorflow as tf                  # 引入TensorFlow框架\n",
    "import numpy as np                       # 引入NumPy库，用于数值计算\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # 用于文本预处理的分词器\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # 用于填充文本序列，使其具有相同长度\n",
    "from tensorflow.keras.models import Sequential  # 用于构建模型的线性层叠\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D  # 各种神经网络层\n",
    "\n",
    "# 示例数据\n",
    "texts = [\"I love machine learning\", \n",
    "         \"I hate coding bugs\", \n",
    "         \"Deep learning is fascinating\", \n",
    "         \"Programming is like magic\"]  # 输入的文本数据\n",
    "labels = [1, 0, 1, 1]  # 1表示正面情感，0表示负面情感，这是对应于texts的情感标签\n",
    "\n",
    "# 数据预处理\n",
    "tokenizer = Tokenizer(num_words=50)     # 初始化一个分词器，设置最大词汇量为50\n",
    "tokenizer.fit_on_texts(texts)            # 对输入文本进行拟合，建立词汇索引\n",
    "sequences = tokenizer.texts_to_sequences(texts)  # 将文本转换为数字序列\n",
    "data = pad_sequences(sequences, maxlen=10)  # 对序列进行填充或截断，使其长度为10\n",
    "labels = np.array(labels).reshape(-1, 1)  # 使标签形状为 (batch_size, 1)，方便后续模型训练\n",
    "\n",
    "# 构建CNN模型\n",
    "model = Sequential()  # 初始化一个顺序模型\n",
    "model.add(Embedding(50, 32, input_length=10))  # 添加词嵌入层，设置输入长度为10，嵌入维度为32，最大词汇量为50\n",
    "model.add(Conv1D(32, 3, activation='relu'))    # 添加一维卷积层，32个滤波器，卷积核大小为3，激活函数为ReLU\n",
    "model.add(Conv1D(32, 3, activation='relu'))    # 再添加一维卷积层\n",
    "model.add(GlobalMaxPooling1D())  # 添加全局最大池化层，对每个特征图取最大值\n",
    "model.add(Dense(32, activation='relu'))  # 添加全连接层，32个神经元，激活函数为ReLU\n",
    "model.add(Dense(1, activation='sigmoid'))  # 添加输出层，1个神经元，使用sigmoid激活函数进行二分类\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # 使用adam优化器，二元交叉熵损失函数，并监控准确性\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(data, labels, epochs=30, verbose=2)  # 使用数据和标签训练模型，进行30轮迭代，verbose=2表示每轮打印一次训练日志\n",
    "\n",
    "# 预测\n",
    "predictions = model.predict(data)  # 使用模型对输入数据进行预测\n",
    "predicted_labels = [1 if p > 0.5 else 0 for p in predictions]  # 将预测值转换为标签，阈值设为0.5\n",
    "\n",
    "predicted_labels  # 输出预测得到的标签\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
